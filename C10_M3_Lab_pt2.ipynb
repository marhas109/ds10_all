{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jywL0obgRlw-"
      },
      "source": [
        "# Lab: CV w/CNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJ6dUzubRsOh"
      },
      "source": [
        "# Part 1: Libraries & Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Libraries"
      ],
      "metadata": {
        "id": "JjINiDkvGQQG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bring in the germane libraries."
      ],
      "metadata": {
        "id": "recLRvwxGVA9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVnFH3H_UbFt"
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# TensorFlow / Keras functions\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential, Input, Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Data"
      ],
      "metadata": {
        "id": "6unqE6FBGYVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and fetch the data with the following Python code (Note: We will use faces.images for X.)"
      ],
      "metadata": {
        "id": "mm_J-4J1GASN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRX8ylFSUVA4"
      },
      "outputs": [],
      "source": [
        "# Load the data\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "faces = fetch_olivetti_faces()\n",
        "X = faces.images\n",
        "y = faces.target.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZWZ8otuUZql"
      },
      "source": [
        "### Step 3: Sample Image"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select an image from this dataset and display it (Hint: Use the plt.cm.gray color map with plt.imshow function)."
      ],
      "metadata": {
        "id": "tMxFtuNOGfpW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwuyDTqoRk2M"
      },
      "outputs": [],
      "source": [
        "# Selecting an image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Training and testing sets"
      ],
      "metadata": {
        "id": "i5x178whGiKb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7kO-EkjRuV0"
      },
      "source": [
        "Setup training and testing sets . Use a 50/50 split for each class (5 training images and 5 test images per person). Print the dimension of each of the feature (image) matrices. Because this is a small dataset, we will also use the test set for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1xIc8EvRx7s"
      },
      "outputs": [],
      "source": [
        "# Creating the training and testing sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Vector conversion"
      ],
      "metadata": {
        "id": "kPW6VfgSGsco"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0eyESn7RyKC"
      },
      "source": [
        "Convert the vector of response variables to a matrix with 40 columns, with indicators for which person it is (one-hot encoded vectors). Print the dimensions of the new response vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKmrJh9KR0_m"
      },
      "outputs": [],
      "source": [
        "# Conversion\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Reshape arrays"
      ],
      "metadata": {
        "id": "vi59OouIGyo3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XYDvxfkLR1Ip"
      },
      "source": [
        "Reshape the image arrays so that they have 4 dimensions: (number of images, width of image, height of image, number of channels). For example, the array of training images should be (200, 64, 64, 1). Print the dimensions of the new image arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf25ODmuR3Xv"
      },
      "outputs": [],
      "source": [
        "# Reshape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Model 1"
      ],
      "metadata": {
        "id": "9I2zNS95G5-8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Model 1's Architecture"
      ],
      "metadata": {
        "id": "yLaCrZTbHCOb"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGVayoY6R9qW"
      },
      "source": [
        "Fit a convolutional neural network using the following architecture, and print the output from training.\n",
        "*   1 convolutional layer with:\n",
        "  * 16 filters (neurons)\n",
        "  * a window size of 3\n",
        "  * stride size of 1\n",
        "  * ReLU activation function\n",
        "  * padding so that the feature is the same size as the original image\n",
        "*   1 max pooling layer with:\n",
        "  * window size of 2\n",
        "  * stride size of 2\n",
        "  * no padding\n",
        "*   1 fully connected output layer with:\n",
        "  * 40 nodes for each face to predict\n",
        "  * softmax activation function\n",
        "*   For training, use the Adam optimizer, 20 epochs, a batch size of 10, and the categorical cross entropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNRrFEt9TXa-"
      },
      "outputs": [],
      "source": [
        "input_tensor = Input(shape=(64, 64, 1))\n",
        "\n",
        "# Convolution Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym9sJ-ymB4Vh"
      },
      "outputs": [],
      "source": [
        "# Compiling model1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Model 1's loss and accuracy"
      ],
      "metadata": {
        "id": "UfV41DrcHQP2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUnYAtTATZZR"
      },
      "source": [
        "Print the loss and accuracy on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKL21AE-TcHc"
      },
      "outputs": [],
      "source": [
        "# Loss and Accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 9: Print image"
      ],
      "metadata": {
        "id": "wY59iuu2HXYm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWG7IwKaTcW1"
      },
      "source": [
        "Pick one of the images from the test set, and print the image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thij7my1TfTu"
      },
      "outputs": [],
      "source": [
        "# An image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 10: Feature maps"
      ],
      "metadata": {
        "id": "bPSOU-8-HdNz"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpH0oWNMTfDF"
      },
      "source": [
        "For the image you selected in (9), print the images of the feature maps from both the convolutional and pooling layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQo5cA2HTy-R"
      },
      "outputs": [],
      "source": [
        "# Feature maps\n",
        "\n",
        "\n",
        "# For loop\n",
        "\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Model 2\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "03smYgkoHsaM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 11: Model 2's Architecture"
      ],
      "metadata": {
        "id": "Ep6vVXJIHjAx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enx2SdvSTzJh"
      },
      "source": [
        "Fit the model from (7) again, but this time use a window size of 9 for the convolution layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WJi0y9JJT1eE"
      },
      "outputs": [],
      "source": [
        "# Change model1 so that it has a window size of 9.\n",
        "\n",
        "# Convolution Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXMSP3MpL9CB"
      },
      "outputs": [],
      "source": [
        "# Compiling model2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 12: Model 2's loss and accuracy"
      ],
      "metadata": {
        "id": "IzBsPvvmH7Jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the loss accuracy on the test set."
      ],
      "metadata": {
        "id": "EjjSLLlxIA3b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocO0ChgsL_uz"
      },
      "outputs": [],
      "source": [
        "# Loss and Accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 13: Feature Maps"
      ],
      "metadata": {
        "id": "0KHQVCxpITQk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y83PWNzT1mm"
      },
      "source": [
        "Print the feature maps for the model in for the same image you used in (9) and (10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "muRzPg1sT4O1"
      },
      "outputs": [],
      "source": [
        "# Feature maps\n",
        "\n",
        "\n",
        "# For loop\n",
        "\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part IV: Model comparison & model optimization\n"
      ],
      "metadata": {
        "id": "BjL3BA6-ItMF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 14: Model comparison"
      ],
      "metadata": {
        "id": "7FXOaoFTImsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment on the differences in the features maps between this model and the previous one. Which network gave better predictions on the test set?"
      ],
      "metadata": {
        "id": "ktCP9E6kIlmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 15: Model 3- Optimized neural network"
      ],
      "metadata": {
        "id": "ym0smJg0I17o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWEczwfGT4V7"
      },
      "source": [
        "Optimize the neural network to improve the accuracy on the test set. You should try to get a better accuracy than both of the previous models.  Consider changing the following, then print the accuracy on the test set:\n",
        "*   Number of convolutional and pooling layers\n",
        "*   Number of filters in the convolutional layer\n",
        "*   Window size\n",
        "*   Number of fully connected layers and neurons\n",
        "*   Regularization (L1/L2 penalty, dropout, early stopping)\n",
        "*   Number of epochs and batch size\n",
        "\n",
        "Call this model `model3`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rghPKiRoUCMg"
      },
      "outputs": [],
      "source": [
        "# Convolution Neural Network Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0KV2PilO0Vf"
      },
      "outputs": [],
      "source": [
        "# Compiling model3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 16: Reflection on Model 3"
      ],
      "metadata": {
        "id": "9ND8Z9cEJJPP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1UTNfw6UCWs"
      },
      "source": [
        "Write a few sentences describing how you optimized the model in this part. What worked well?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}